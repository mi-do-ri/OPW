{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "TloS2KHSB_yX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import time\n",
        "from scipy.spatial.distance import cdist\n",
        "from sklearn.metrics import average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "-Z9T3c0UD4ya"
      },
      "outputs": [],
      "source": [
        "def RVSML_OT_Learning(trainset, templatenum, lambda_val, delta = 1, max_nIter = 20, err_limit = 1.0e-6):\n",
        "    lambda1=torch.tensor(0.5, requires_grad=True)\n",
        "    lambda2=torch.tensor(0.5, requires_grad=True)\n",
        "    learning_rate = 1e-1\n",
        "    optimizer = torch.optim.Adam([lambda1, lambda2], learning_rate)\n",
        "\n",
        "    classnum = len(trainset)\n",
        "    downdim = classnum * templatenum\n",
        "    dim = len(trainset[0][0][0])\n",
        "    traindownset = [None] * classnum\n",
        "\n",
        "    trainsetnum = [0] * classnum\n",
        "    virtual_sequence = [None] * classnum\n",
        "    active_dim = 0\n",
        "\n",
        "    for c in range(0, classnum-1):\n",
        "        trainsetnum[c] = len(trainset[c])\n",
        "        virtual_sequence[c] = torch.zeros((templatenum, downdim))\n",
        "        for a_d in range(0, templatenum-1):\n",
        "            active_dim += 1\n",
        "            virtual_sequence[c][a_d][active_dim] = 1\n",
        "\n",
        "    R_A = torch.zeros((dim, dim))\n",
        "    R_B = torch.zeros((dim, downdim))\n",
        "    N = sum(trainsetnum)\n",
        "    for c in range(classnum):\n",
        "        for n in range(trainsetnum[c]):\n",
        "            seqlen = len(trainset[c][n])\n",
        "            T_ini = torch.ones((seqlen, templatenum)) / (seqlen * templatenum)\n",
        "            for i in range(seqlen):\n",
        "                trainset[c][n][i] = torch.tensor(trainset[c][n][i])\n",
        "                temp_ra = torch.ger(trainset[c][n][i], trainset[c][n][i])\n",
        "                for j in range(templatenum):\n",
        "                    R_A += T_ini[i, j] * temp_ra\n",
        "                    R_B += T_ini[i, j] * torch.ger(trainset[c][n][i], virtual_sequence[c][j])\n",
        "            trainset[c][n] = torch.stack(trainset[c][n])\n",
        "\n",
        "    R_I = R_A + lambda_val * N * torch.eye(dim)\n",
        "    L = torch.linalg.solve(R_I, R_B)\n",
        "\n",
        "    loss_old = 1e8\n",
        "    values_loss = []\n",
        "\n",
        "    for nIter in range(max_nIter):\n",
        "        loss = 0\n",
        "        R_A = torch.zeros((dim, dim))\n",
        "        R_B = torch.zeros((dim, downdim))\n",
        "        N = np.sum(trainsetnum)\n",
        "    \n",
        "        for c in range(classnum):\n",
        "            traindownset[c] = [None] * trainsetnum[c]\n",
        "            for n in range(trainsetnum[c]):\n",
        "                seqlen = len(trainset[c][n])\n",
        "\n",
        "                traindownset[c][n] = torch.matmul(trainset[c][n], L)\n",
        "                dist, T = OPW_w(torch.matmul(trainset[c][n], L), virtual_sequence[c], verbose=0, lambda1=lambda1, lambda2=lambda2)\n",
        "                # print(torch.tensor(T).shape)\n",
        "                # values_T.append(torch.tensor(T).numpy)\n",
        "                loss -= dist\n",
        "                \n",
        "                for i in range(seqlen):\n",
        "                    temp_ra = torch.ger(trainset[c][n][i], trainset[c][n][i])\n",
        "                    for j in range(templatenum):\n",
        "                        \n",
        "                        R_A += ((T[i, j] * temp_ra))\n",
        "                        R_B += (T[i, j] * torch.ger(trainset[c][n][i], virtual_sequence[c][j]))\n",
        "\n",
        "        \n",
        "        loss = loss / N - torch.trace(torch.matmul(L.t(), L))\n",
        "        values_loss.append(loss.detach().numpy())\n",
        "        if abs(loss - loss_old) < err_limit:\n",
        "            break\n",
        "        else:\n",
        "            loss_old = loss\n",
        "        print(loss)\n",
        "        \n",
        "    \n",
        "        R_I = R_A + lambda_val * N * torch.eye(dim)\n",
        "        L = torch.linalg.solve(R_I, R_B)\n",
        "    print(values_loss)\n",
        "    plt.plot(values_loss)\n",
        "    plt.xlabel('Step/Epoch')\n",
        "    plt.ylabel('Values_Loss')\n",
        "    plt.title('Values_Loss over Steps/Epochs')\n",
        "    plt.show()  \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(lambda1)\n",
        "    print(lambda2)\n",
        "    return L, traindownset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "RVlDqTf8B_yZ"
      },
      "outputs": [],
      "source": [
        "def OPW_w(x: torch.Tensor, y: torch.Tensor, a: torch.Tensor = None, b: torch.Tensor = None, std=1, verbose=0, lambda1=0.1, lambda2=10,\n",
        "          tol=.5e-2, maxIter=20, p_norm='inf', metric='sqreuclidean'):\n",
        "          \n",
        "    assert y.size(1) == x.size(1), \"The dimensions of instances in the input sequences must be the same!\"\n",
        "    N = x.size(0)\n",
        "    M = y.size(0)\n",
        "    col_x = torch.arange(1, N+1)/N\n",
        "    col_x = col_x.view(N, 1)\n",
        "    col_y = torch.arange(1, M+1)/M\n",
        "    relative_pos = col_x-col_y\n",
        "\n",
        "    l = torch.abs(relative_pos) / ((1/N**2 + 1/M**2)**0.5)\n",
        "    P = torch.exp(-l**2/(2*std**2)) / (std*(2*np.pi)**0.5)\n",
        "\n",
        "    S = lambda1 / (relative_pos**2 + 1)\n",
        "\n",
        "    D = pdist2(x, y, metric=metric)\n",
        "\n",
        "    K = P * torch.exp((S - D) / lambda2)\n",
        "\n",
        "    if a is None:\n",
        "        a = torch.ones(N, 1) / N\n",
        "\n",
        "    ainvK = K / a   # [N, M]\n",
        "\n",
        "    iter = 0\n",
        "    u = torch.ones(N, 1) / N\n",
        "\n",
        "    if b is None:\n",
        "        b = torch.ones(M, 1) / M\n",
        "    while iter < maxIter:\n",
        "        # Ensure tensors have the correct shape and scalar type\n",
        "        ainvK = ainvK.to(torch.float32)\n",
        "        b = b.to(torch.float32)\n",
        "        K = K.to(torch.float32)\n",
        "        u = u.to(torch.float32)\n",
        "\n",
        "        # Perform the operations\n",
        "        K_transpose = K.t()\n",
        "        temp = b / torch.matmul(K_transpose, u)\n",
        "        temp2 = torch.matmul(ainvK, temp)\n",
        "        u = 1.0 / temp2\n",
        "        \n",
        "        iter += 1\n",
        "        if iter % 20 == 1 or iter == maxIter:\n",
        "            v = b / torch.matmul(K.T, u)    # [M, 1]\n",
        "            u = 1 / torch.matmul(ainvK, v)  # [N, 1]\n",
        "\n",
        "            criterion = torch.sum(torch.abs(v * torch.matmul(K.T, u) - b), dim=0)\n",
        "            criterion = criterion.norm(p=float(p_norm))\n",
        "            if abs(criterion) < tol:\n",
        "                break\n",
        "\n",
        "            iter += 1\n",
        "            if verbose > 0:\n",
        "                print(f\"Iteration : {iter}, Criterion: {criterion}\")\n",
        "    \n",
        "    U = K * D   # [N, M]\n",
        "    \n",
        "    dist = torch.sum(u.double() * torch.matmul(U.double(), v.double()), dim=0)\n",
        "    T = v.T.double() * (u.double() * K.double())\n",
        " \n",
        "    return dist, T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "def OPW(x: torch.Tensor, y: torch.Tensor, a: torch.Tensor = None, b: torch.Tensor = None, std=1, verbose=0, lambda1=0.1, lambda2=10,\n",
        "          tol=.5e-2, maxIter=20, p_norm='inf', metric='sqreuclidean'):\n",
        "          \n",
        "    assert y.size(1) == x.size(1), \"The dimensions of instances in the input sequences must be the same!\"\n",
        "    N = x.size(0)\n",
        "    M = y.size(0)\n",
        "    col_x = torch.arange(1, N+1)/N\n",
        "    col_x = col_x.view(N, 1)\n",
        "    col_y = torch.arange(1, M+1)/M\n",
        "    relative_pos = col_x-col_y\n",
        "\n",
        "    l = torch.abs(relative_pos) / ((1/N**2 + 1/M**2)**0.5)\n",
        "    P = torch.exp(-l**2/(2*std**2)) / (std*(2*np.pi)**0.5)\n",
        "\n",
        "    S = lambda1 / (relative_pos**2 + 1)\n",
        "\n",
        "    D = pdist2(x, y, metric=metric)\n",
        "\n",
        "    K = P * torch.exp((S - D) / lambda2)\n",
        "\n",
        "    if a is None:\n",
        "        a = torch.ones(N, 1) / N\n",
        "\n",
        "    ainvK = K / a   # [N, M]\n",
        "\n",
        "    iter = 0\n",
        "    u = torch.ones(N, 1) / N\n",
        "\n",
        "    if b is None:\n",
        "        b = torch.ones(M, 1) / M\n",
        "    while iter < maxIter:\n",
        "\n",
        "        # Perform the operations\n",
        "        K_transpose = K.t()\n",
        "        temp = b / torch.matmul(K_transpose, u)\n",
        "        temp2 = torch.matmul(ainvK, temp)\n",
        "        u = 1.0 / temp2\n",
        "        \n",
        "        iter += 1\n",
        "        if iter % 20 == 1 or iter == maxIter:\n",
        "            v = b / torch.matmul(K.T, u)    # [M, 1]\n",
        "            u = 1 / torch.matmul(ainvK, v)  # [N, 1]\n",
        "\n",
        "            criterion = torch.sum(torch.abs(v * torch.matmul(K.T, u) - b), dim=0)\n",
        "            criterion = criterion.norm(p=float(p_norm))\n",
        "            if abs(criterion) < tol:\n",
        "                break\n",
        "\n",
        "            iter += 1\n",
        "            if verbose > 0:\n",
        "                print(f\"Iteration : {iter}, Criterion: {criterion}\")\n",
        "    \n",
        "    U = K * D   # [N, M]\n",
        "    \n",
        "    dist = torch.sum(u.double() * torch.matmul(U.double(), v.double()), dim=0)\n",
        "    T = v.T.double() * (u.double() * K.double())\n",
        " \n",
        "    return dist, T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "UxGHJJY9iWm_"
      },
      "outputs": [],
      "source": [
        "def pdist2(X, Y, metric='sqreuclidean'):\n",
        "    if metric.lower() == 'sqreuclidean':\n",
        "        return distEucSqr(X, Y)\n",
        "    elif metric.lower() == 'euclidean':\n",
        "        return torch.sqrt(distEucSqr(X, Y))\n",
        "    elif metric.lower() == 'L1':\n",
        "        return distL1(X, Y)\n",
        "    elif metric.lower() == 'cosine':\n",
        "        return distCosine(X, Y)\n",
        "    elif metric.lower() == 'emd':\n",
        "        return distEmd(X, Y)\n",
        "    elif metric.lower() == 'chisqr':\n",
        "        return distChiSqr(X, Y)\n",
        "    else:\n",
        "        raise NotImplementedError(f'pdist - unknown metric: {metric}')\n",
        "\n",
        "\n",
        "def distL1(x: torch.Tensor, y: torch.Tensor):\n",
        "    return torch.abs(x.unsqueeze(1) - y).sum(dim=-1)\n",
        "\n",
        "\n",
        "def distCosine(x: torch.Tensor, y: torch.Tensor, eps=1e-8):\n",
        "    assert x.dtype == torch.float or y.dtype == torch.float, \"Inputs must be of type float\"\n",
        "    cos = torch.nn.CosineSimilarity(dim=-1, eps=eps)\n",
        "    return 1 - cos(x.unsqueeze(1), y)\n",
        "\n",
        "\n",
        "def distEmd(x: torch.Tensor, y: torch.Tensor):\n",
        "    x_cdf = torch.cumsum(x, dim=-1)\n",
        "    y_cdf = torch.cumsum(y, dim=-1)\n",
        "\n",
        "    return torch.abs(x_cdf.unsqueeze(1) - y_cdf).sum(dim=-1)\n",
        "\n",
        "\n",
        "def distEucSqr(x: torch.Tensor, y: torch.Tensor):\n",
        "    return torch.cdist(x, y, p=2)**2\n",
        "\n",
        "\n",
        "def distChiSqr(x: torch.Tensor, y: torch.Tensor, eps=1e-10):\n",
        "    a = x.unsqueeze(1) + y\n",
        "    b = x.unsqueeze(1) - y\n",
        "    return (b**2 / (a + eps)).sum(dim=-1) / 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "gVyo1G30paHX"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "def NNClassifier(classnum, trainset, trainsetnum, testsetdata, testsetdatanum, testsetlabel, \n",
        "                 lambda1 = 0.1, lambda2 = 10, delta = 1):\n",
        "\n",
        "    trainsetdata =  [None] * 1000 # trainsetdatanum\n",
        "    trainsetlabel = torch.zeros((1000, 1))\n",
        "    sample_count = 0\n",
        "\n",
        "    for c in range(classnum):\n",
        "        for per_sample_count in range(trainsetnum[c]):\n",
        "            trainsetdata[sample_count] = trainset[c][per_sample_count]\n",
        "            trainsetlabel[sample_count] = c\n",
        "            sample_count += 1\n",
        "            \n",
        "\n",
        "    # def getLabel(classid):\n",
        "    #     X = torch.zeros((len(classid), torch.max(classid))) - 1\n",
        "    #     for i in range(1, torch.max(classid) + 1):\n",
        "    #         indx = torch.where(classid == i)[0]\n",
        "    #         X[indx, i-1] = 1\n",
        "    #     return X\n",
        "    testsetlabelori = testsetlabel.clone()\n",
        "    # testsetlabel = getLabel(testsetlabelori)\n",
        "    # trainsetlabelfull = getLabel(trainsetlabel)\n",
        "    \n",
        "    encoder = OneHotEncoder(sparse=False)\n",
        "    \n",
        "    testsetlabel_reshaped = testsetlabel.reshape(-1,1)\n",
        "    trainsetlabel_reshaped = trainsetlabel.reshape(-1,1)\n",
        "    \n",
        "    testsetlabel = encoder.fit_transform(testsetlabel_reshaped)\n",
        "    trainsetlabelfull = encoder.fit_transform(trainsetlabel_reshaped)\n",
        "    \n",
        "\n",
        "    k_pool = [1, 3, 5, 7, 9, 11, 15, 30]\n",
        "    k_num = len(k_pool)\n",
        "    Acc = torch.zeros((k_num, 1))\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    dis_totrain_scores = torch.zeros((1000, testsetdatanum))\n",
        "    ClassLabel = torch.arange(0, classnum)\n",
        "    dis_ap = torch.zeros(testsetdatanum)\n",
        "\n",
        "    rightnum = torch.zeros(k_num)\n",
        "    for j in range(testsetdatanum):\n",
        "        testsetdata[j] = torch.tensor(testsetdata[j])\n",
        "        for m2 in range(1000):\n",
        "            # [Dist, D, matchlength, w] = dtw2(trainsetdata[m2].T, testsetdata[j].T)\n",
        "            # [Dist, T] = Sinkhorn_distance(trainsetdata[m2], testsetdata[j], lambda, 0)\n",
        "            [Dist, T] = OPW(torch.tensor(trainsetdata[m2]), testsetdata[j], lambda1, lambda2)\n",
        "            dis_totrain_scores[m2, j] = Dist\n",
        "            if np.isnan(Dist):\n",
        "                print('Not a number!')\n",
        "        \n",
        "        distm, index = torch.sort(dis_totrain_scores[:, j])\n",
        "        \n",
        "        for k_count in range(k_num):\n",
        "            cnt = torch.zeros(classnum)\n",
        "            for temp_i in range(k_pool[k_count]):\n",
        "                ind = torch.where(ClassLabel == trainsetlabel[index[temp_i]])[0][0]\n",
        "                cnt[ind] += 1\n",
        "            distm2, ind = torch.max(cnt), torch.argmax(cnt)\n",
        "            predict = ClassLabel[ind]\n",
        "            predict = predict.item()\n",
        "            if predict == testsetlabelori[j]:\n",
        "                rightnum[k_count] += 1\n",
        "        \n",
        "        temp_dis = -dis_totrain_scores[:, j]\n",
        "        temp_dis[np.isnan(temp_dis)] = 0\n",
        "        average_precision = average_precision_score(trainsetlabelfull[:, testsetlabelori[j]], temp_dis)\n",
        "        dis_ap[j] = average_precision\n",
        "        \n",
        "        Acc = rightnum / testsetdatanum\n",
        "        Map = torch.mean(dis_ap)\n",
        "\n",
        "        knn_time = time.time() - start_time\n",
        "        knn_averagetime = knn_time / testsetdatanum\n",
        "\n",
        "    return Map, Acc, knn_averagetime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "bqcpd57pS9AP"
      },
      "outputs": [],
      "source": [
        "def get_utterances(path):\n",
        "  X = []\n",
        "  utterances = []\n",
        "  count = 0\n",
        "  with open(path, 'r') as f:\n",
        "      length_X = len([line for line in f.read().splitlines()])\n",
        "  with open(path, 'r') as f:\n",
        "      for line in f.read().splitlines():\n",
        "          count += 1\n",
        "          frame = [-abs(float(i)) if i.startswith('-') else abs(float(i)) for i in line.split()]\n",
        "          if len(frame) > 0:\n",
        "            utterances.append(frame)\n",
        "            if count == length_X:\n",
        "              X.append(utterances)\n",
        "          else:\n",
        "            if len(utterances) > 0:\n",
        "              X.append(utterances)\n",
        "              utterances = []\n",
        "          # if len(X) == 660*2: \n",
        "          #    break\n",
        "  return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdYUERkvTIZw",
        "outputId": "8b4ce593-de69-46fc-93c3-674b63764f8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training sample: 6600\n",
            "Number of testing sample: 2200\n"
          ]
        }
      ],
      "source": [
        "X_train = get_utterances(path=\"E:/Documents/Tài liệu học tập/DS Lab/OT/OWD/data sets/Train_Arabic_Digit.txt\")\n",
        "X_test = get_utterances(path=\"E:/Documents/Tài liệu học tập/DS Lab/OT/OWD/data sets/Test_Arabic_Digit.txt\")\n",
        "print(f\"Number of training sample: {len(X_train)}\")\n",
        "print(f\"Number of testing sample: {len(X_test)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "-ihewS5MTzQc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import json \n",
        "\n",
        "n_class = torch.Tensor(torch.arange(0, 10)).view(10, 1)\n",
        "y_train = n_class.expand_as(torch.empty((10, 660))).contiguous().view(6600)\n",
        "y_test = n_class.expand_as(torch.empty((10, 220))).contiguous().view(2200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JmIYiV7_Avj",
        "outputId": "0f99fdcb-cf49-479f-a179-23c4520a00ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 0, 0,  ..., 9, 9, 9])"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "Nnr9S93YNN3w"
      },
      "outputs": [],
      "source": [
        "with open('fe.json', 'w') as f:\n",
        "    json.dump(3, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "EUcXUT-ApDR9"
      },
      "outputs": [],
      "source": [
        "dataset = [(data_sample, class_label) for data_sample, class_label in zip(X_train, y_train)]\n",
        "\n",
        "# Dictionary to store the selected samples\n",
        "selected_samples = {class_label: [] for class_label in range(10)}\n",
        "\n",
        "# Iterate over each class\n",
        "for class_label in range(10):\n",
        "    # Filter the dataset for the current class\n",
        "    filtered_data = [sample for sample in dataset if sample[1] == class_label]\n",
        "    \n",
        "    # Randomly select 100 samples from the filtered dataset\n",
        "    selected_samples[class_label] = random.sample(filtered_data, 100)\n",
        "\n",
        "# Print the selected samples\n",
        "# for class_label, samples in selected_samples.items():\n",
        "#     print(f\"Class {class_label}:\")\n",
        "#     for sample in samples:\n",
        "#         print(sample)\n",
        "    # print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "bWNFPEr2xyx9"
      },
      "outputs": [],
      "source": [
        "testsetdata = X_test\n",
        "testsetlabel = y_test\n",
        "testsetdatanum = len(X_test)\n",
        "\n",
        "trainsetdata = []\n",
        "trainsetlabel = []\n",
        "for class_label, samples in selected_samples.items():\n",
        "    for sample in samples:\n",
        "        trainsetdata.append(sample[0])\n",
        "        trainsetlabel.append(sample[1])\n",
        "\n",
        "trainsetdatanum = len(trainsetdata)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "jPRNl1YN2iFm"
      },
      "outputs": [],
      "source": [
        "trainset = []\n",
        "trainset_cell = []\n",
        "trainsetnum = []\n",
        "\n",
        "for i, data_point in enumerate(trainsetdata, 1):\n",
        "    trainset_cell.append(data_point)\n",
        "    \n",
        "    if i % 100 == 0 or i == len(X_train):\n",
        "        trainset.append(trainset_cell)\n",
        "        trainsetnum.append(len(trainset_cell))\n",
        "        trainset_cell = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "-FEJD9QM2O4g",
        "outputId": "440b5b61-9bda-4998-ea36-d775523188c3"
      },
      "outputs": [],
      "source": [
        "classnum = 10\n",
        "dim = 40\n",
        "CVAL = 1\n",
        "\n",
        "templatenum = 4     \n",
        "lambda_val = 0.01\n",
        "start_time = time.time()\n",
        "\n",
        "testdownsetdata = [None] * testsetdatanum\n",
        "\n",
        "L, traindownset = RVSML_OT_Learning(trainset, templatenum, lambda_val, delta = 1, max_nIter = 20, err_limit = 1.0e-6)\n",
        "\n",
        "for j in range(testsetdatanum):\n",
        "    testsetdata[j] = torch.tensor(testsetdata[j])\n",
        "    testdownsetdata[j] = torch.matmul(testsetdata[j], L)\n",
        "RVSML_opw_time = time.time() - start_time\n",
        "print(type(trainset[0][0]))\n",
        "\n",
        "# for j in range(classnum):\n",
        "#         traindownset[j] = [None] * trainsetnum[j]\n",
        "#         for m in range(trainsetnum[j]):\n",
        "#             seqlen = len(trainset[j][m])\n",
        "#             for i in range(seqlen):\n",
        "#                 trainset[j][m][i] = torch.tensor(trainset[j][m][i])\n",
        "#             trainset[j][m] = torch.cat((trainset[j][m], trainset[j][m][i]), dim=1)\n",
        "#             traindownset[j][m] = trainset[j][m] * L\n",
        "\n",
        "\n",
        "\n",
        "Map, Acc, knn_averagetime = NNClassifier(classnum, trainset, trainsetnum, testsetdata, testsetdatanum, testsetlabel, \n",
        "                 lambda1 = 0.1, lambda2 = 10, delta = 1)\n",
        "RVSML_opw_acc_1 = Acc[0]\n",
        "\n",
        "print(f\"Training time of RVSML instantiated by OPW is {RVSML_opw_time:.4f}\")\n",
        "print(\"Classification using 1 nearest neighbor classifier with OPW distance:\")\n",
        "# print(f\"MAP is {RVSML_opw_map:.4f}\")\n",
        "print(f\"Accuracy is {RVSML_opw_acc_1:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
